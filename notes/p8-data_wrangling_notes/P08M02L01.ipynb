{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 02: Gathering Data\n",
    "\n",
    "\n",
    "### Lesson 01: Gathering Data\n",
    "\n",
    "> Gather data from various sources and a variety of file formats using Python. Rotten Tomatoes ratings, Roger Ebert reviews, and Wikipedia movie poster images make up the dataset for this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01. Introduction\n",
    "\n",
    "You're going to master gathering data. Depending on your project, gathering data varies a lot. Data you need may be spread across dozens of sources and in different file formats, which might be the most challenging part of working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02. Lesson Outline\n",
    "\n",
    "Gathering data is the first step in data wrangling. Before gathering, we have no data, and after it, we do.\n",
    "\n",
    "When you do find your data, it's not unusual for it to be spread across several different sources and file formats, which makes things tricky when organizing the data in your programming environment.\n",
    "\n",
    "This lesson will be structured as follows:\n",
    "\n",
    "1. First, we'll pose a few questions.\n",
    "2. Then you'll explore the source of each piece of data we need to answer those questions, each piece from a different source and in a different format.\n",
    "3. Then you'll learn about the structure of each file format.\n",
    "4. Then you'll learn how to handle that file format using Python and its libraries.\n",
    "5. Then you'll actually gather each piece of data to later join together to create your master dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03. Dataset: Finding the Best Movies\n",
    "\n",
    "For lots of people, Roger Ebert's was the only review they needed because he explained the movie in such a way that they would know whether they would like it or not, his opinion notwithstanding.\n",
    "\n",
    "wouldn't it be cool to compare this critic's score and also the audience score for all of these movies to see which movie really truly is the best? Also to find the worst best movie if you will.\n",
    "\n",
    "I'm picturing a scatterplot with four quadrants, like this one, but with different axis labels and values. We'd have audience score on the horizontal axis and critics score on the vertical one.\n",
    "\n",
    "Wouldn't it be neat if we had a word cloud for each of the movies in that top 100 list with Roger Ebert's review text in that word cloud for each movie? so we could take the movie poster for each movie and surround it with a stencil and then put the word cloud around the poster image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04. Navigating Your Working Directory and File I/O\n",
    "\n",
    "1. Command Line\n",
    "\n",
    "Before you continue on with this lesson, make sure you are comfortable working with your computer's command line interface to access files and folders, and also with reading and writing to files (i.e. part of File I/O or input/output) in Python.\n",
    "\n",
    "For the command line interface, here are three excellent resources that I recommend. Pick whichever suits you best:\n",
    "\n",
    "* Our short (Linux Command Line Basics)https://www.udacity.com/course/linux-command-line-basics--ud595) course (for Linux and Mac users)\n",
    "* [Navigating the Terminal: A Gentle Introduction](Navigating the Terminal: A Gentle Introduction) by Marius Masalar (for Mac users)\n",
    "* [Command Prompt - How to use the simple, basic commands](http://www.digitalcitizen.life/command-prompt-how-use-basic-commands) by Codrut Neagu (for Windows users)\n",
    "\n",
    "\n",
    "2. File I/O\n",
    "\n",
    "For reading from and writing to files in Python:\n",
    "\n",
    "The \"Reading from a File\" concept in Lesson 5 (\"Files and Modules\") of our [Introduction to Python](https://www.udacity.com/course/introduction-to-python--ud1110) course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 05. Source: Files on Hand\n",
    "\n",
    "Internal data from a database can be downloaded programmatically from the file storage systems (like Google Drive) for some companies, though it is often trickier than downloading a file hosted on a web page. \n",
    "\n",
    "In practice, internal files aren't often downloaded programmatically for wrangling and analysis/visualization/modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 06. Flat File Structure\n",
    "\n",
    "Flat files contain tabular data in plain text format with one data record per line and each record or line having one or more fields. These fields are separated by delimiters, like commas, tabs, or colons.\n",
    "\n",
    "**Advantages of flat files include**:\n",
    "\n",
    "* They're text files and therefore human readable.\n",
    "Lightweight.\n",
    "* Simple to understand.\n",
    "* Software that can read/write text files is ubiquitous, like text editors.\n",
    "* Great for small datasets.\n",
    "\n",
    "**Disadvantages of flat files**, in comparison to relational databases, for example, include:\n",
    "\n",
    "* Lack of standards.\n",
    "* Data redundancy.\n",
    "* Sharing data can be cumbersome.\n",
    "* Not great for large datasets (see \"When does small become large?\" in the Cornell link in More Information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 07. Flat Files in Python\n",
    "\n",
    "In the Jupyter Notebook below, import the Rotten Tomatoes Top 100 Movies of All Time TSV file ('bestofrt.tsv') into a pandas DataFrame. Hint: read up on the *sep* parameter in the read_csv documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranking</th>\n",
       "      <th>critic_score</th>\n",
       "      <th>title</th>\n",
       "      <th>number_of_critic_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>The Wizard of Oz (1939)</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>The Third Man (1949)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>Get Out (2017)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>Mad Max: Fury Road (2015)</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranking  critic_score                      title  number_of_critic_ratings\n",
       "0        1            99    The Wizard of Oz (1939)                       110\n",
       "1        2           100        Citizen Kane (1941)                        75\n",
       "2        3           100       The Third Man (1949)                        77\n",
       "3        4            99             Get Out (2017)                       282\n",
       "4        5            97  Mad Max: Fury Road (2015)                       370"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('bestofrt.tsv', sep='\\t')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      "ranking                     100 non-null int64\n",
      "critic_score                100 non-null int64\n",
      "title                       100 non-null object\n",
      "number_of_critic_ratings    100 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 08. Source: Web Scraping\n",
    "\n",
    "Web scraping is a fancy way of saying extracting data from web sites using code.\n",
    "\n",
    "The data that lives on web pages is called HTML, HyperText Markup Language. It's made up of these things called tags which give the web page structure. Because HTML code is just text, these tags and the content within them can be accessed using parsers, and in Python, there is an awesome one called Beautiful Soup. We can download HTML and access it offline, or we can do it in real time over the Internet.\n",
    "\n",
    "The two main ways to work with HTML files are:\n",
    "\n",
    "* Saving the HTML file to your computer (using the Requests library for example) library and reading that file into a BeautifulSoup constructor\n",
    "* Reading the HTML response content directly into a BeautifulSoup constructor (again using the Requests library for example)\n",
    "\n",
    "I've downloaded all of the Rotten Tomatoes HTML files for you and put them in a folder called rt_html in the Jupyter Notebooks in the Udacity classroom. \n",
    "\n",
    "The rt_html folder contains the Rotten Tomatoes HTML for each of the Top 100 Movies of All Time as the list stood at the most recent update of this lesson. I'm giving you these historical files because the ratings will change over time and there will be inconsistencies with the recorded lesson videos. Also, a web page's HTML is known to change over time. Scraping code can break easily when web redesigns occur, which makes scraping brittle and not recommended for projects with longevity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 09. HTML File Structure\n",
    "\n",
    "The Hypertext Markup Language (or HTML) is the language used to create documents for the World Wide Web.\n",
    "\n",
    "If you'd like to learn more, or are feeling like there are knowledge gaps you'd like to fill in, I encourage you to check out Cameron's \"Intro to HTML and CSS\" course. You can find it [here](https://www.udacity.com/course/intro-to-html-and-css--ud304)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. HTML Files in Python\n",
    "\n",
    "With your knowledge of HTML file structure, you're going to use Beautiful Soup to extract our desired Audience Score metric and number of audience ratings, along with the movie title like in the video above.\n",
    "\n",
    "The Jupyter Notebook below contains template code that:\n",
    "\n",
    "* Creates an empty list, df_list, to which dictionaries will be appended. This list of dictionaries will eventually be converted to a pandas DataFrame (this is the [most efficient way of building a DataFrame row by row](https://stackoverflow.com/a/28058264)).\n",
    "* Loops through each movie's Rotten Tomatoes HTML file in the rt_html folder.\n",
    "* Opens each HTML file and passes it into a file handle called file.\n",
    "* Creates a DataFrame called df by converting df_list using the [pd.DataFrame constructor](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('rt_html/et_the_extraterrestrial.html') as file:\n",
    "    soup = BeautifulSoup(file, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E.T. The Extra-Terrestrial(1982)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('title').contents[0][:-len(\" - Rotten Tomatoes\")].replace(u'\\xa0', u'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', class_ = \"audience-score meter\").find('span').contents[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32313030'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_ = \"audience-info hidden-xs superPageFontColor\").find_all(\"div\")[1].contents[-1].strip().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract the title, audience score, \n",
    "# And number of audience ratings in each HTML file \n",
    "import os\n",
    "df_lists = []\n",
    "folder = 'rt_html'\n",
    "for movie_html in os.listdir(folder):\n",
    "    if movie_html[0] == '.':\n",
    "        continue\n",
    "    with open(os.path.join(folder, movie_html)) as file:\n",
    "        soup = BeautifulSoup(file, 'lxml')\n",
    "        title = soup.find('title').contents[0][:-len(\" - Rotten Tomatoes\")].replace(u'\\xa0', u'')\n",
    "        audience_score = soup.find(class_ = \"audience-score meter\").find(class_ = \"superPageFontColor\").contents[0][:-1]\n",
    "        number_of_audience_ratings = soup.find(class_ = \"audience-info hidden-xs superPageFontColor\").find_all(\"div\")[1].contents[-1].strip().replace(',', '')\n",
    "        df_lists.append({'title': title,\n",
    "                         'audience_score': audience_score,\n",
    "                         'number_of_audience_ratings': number_of_audience_ratings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>audience_score</th>\n",
       "      <th>number_of_audience_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zootopia(2016)</td>\n",
       "      <td>92</td>\n",
       "      <td>98633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Treasure of the Sierra Madre(1948)</td>\n",
       "      <td>93</td>\n",
       "      <td>25627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Quiet on the Western Front(1930)</td>\n",
       "      <td>89</td>\n",
       "      <td>17768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rear Window(1954)</td>\n",
       "      <td>95</td>\n",
       "      <td>149458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selma(2015)</td>\n",
       "      <td>86</td>\n",
       "      <td>60533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title audience_score  \\\n",
       "0                          Zootopia(2016)             92   \n",
       "1  The Treasure of the Sierra Madre(1948)             93   \n",
       "2    All Quiet on the Western Front(1930)             89   \n",
       "3                       Rear Window(1954)             95   \n",
       "4                             Selma(2015)             86   \n",
       "\n",
       "  number_of_audience_ratings  \n",
       "0                      98633  \n",
       "1                      25627  \n",
       "2                      17768  \n",
       "3                     149458  \n",
       "4                      60533  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(df_lists, columns = ['title', 'audience_score', 'number_of_audience_ratings'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      "title                         100 non-null object\n",
      "audience_score                100 non-null object\n",
      "number_of_audience_ratings    100 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Flashforward 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(by='title').reset_index(drop=True)\n",
    "df2 = df2.sort_values(by='title').reset_index(drop=True)\n",
    "df = df1.combine_first(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(df.audience_score, df.critic_score);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tableau**\n",
    "\n",
    "You've got audience score on the horizontal axis ranging from 70% to 100%, critics score in the vertical axis ranging from 91% to 100%, well technically, 101, but that's just for visual purposes. Then you've got these reference lines. The vertical one being the median of audience score, which is 90%, and the horizontal reference line is the median of critics score, 98%.\n",
    "\n",
    "* In the top right corner of the screen, we've even got number of audience ratings and number of critic ratings represented visually, too.\n",
    "* Lighter shades of blue mean small number of audience ratings and darker shades of blue means a larger number. And smaller circles mean a smaller number of critic ratings and larger circles mean a larger number of critic ratings.\n",
    "* In the top right corner of the screen, we've got universally loved movies. High audience scores, high critics scores.\n",
    "* In the bottom right corner, we've got critically underrated movies. Audience scores above the median audience score for this top 100 list and critics scores below the median critics score for this top 100 list.\n",
    "* In the top left, we have critically overrated movies. Audiences didn't like these movies as much as critics did, basically.\n",
    "* In the bottom left quadrant, we've got movies that didn't have particularly high critic or audience scores in reference to the movies on this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Source: Downloading Files from the Internet\n",
    "\n",
    "**HTTP (Hypertext Transfer Protocol)**\n",
    "\n",
    "HTTP, the Hypertext Transfer Protocol, is the language that web browsers (like Chrome or Safari) and web servers (basically computers where the contents of a website are stored) speak to each other. Every time you open a web page, or download a file, or watch a video, it's HTTP that makes it possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_name = 'ebert_reviews'\n",
    "#if not os.path.exists(folder_name):\n",
    "#    os.makedirs(folder_name)\n",
    "\n",
    "#url = \"text-urls\"\n",
    "#response = requests.get(url)\n",
    "#with open(oa.path.join(folder_name,\n",
    "#                       url.split('/')[-1]), mode='wb') as file:\n",
    "#    file.write(response.content)\n",
    "#os.listdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebert_review_urls = ['https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9900_1-the-wizard-of-oz-1939-film/1-the-wizard-of-oz-1939-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_2-citizen-kane/2-citizen-kane.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9901_3-the-third-man/3-the-third-man.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_4-get-out-film/4-get-out-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_5-mad-max-fury-road/5-mad-max-fury-road.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9902_6-the-cabinet-of-dr.-caligari/6-the-cabinet-of-dr.-caligari.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_7-all-about-eve/7-all-about-eve.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_8-inside-out-2015-film/8-inside-out-2015-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9903_9-the-godfather/9-the-godfather.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_10-metropolis-1927-film/10-metropolis-1927-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_11-e.t.-the-extra-terrestrial/11-e.t.-the-extra-terrestrial.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_12-modern-times-film/12-modern-times-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9904_14-singin-in-the-rain/14-singin-in-the-rain.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_15-boyhood-film/15-boyhood-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_16-casablanca-film/16-casablanca-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9905_17-moonlight-2016-film/17-moonlight-2016-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_18-psycho-1960-film/18-psycho-1960-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_19-laura-1944-film/19-laura-1944-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9906_20-nosferatu/20-nosferatu.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_21-snow-white-and-the-seven-dwarfs-1937-film/21-snow-white-and-the-seven-dwarfs-1937-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_22-a-hard-day27s-night-film/22-a-hard-day27s-night-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9907_23-la-grande-illusion/23-la-grande-illusion.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_25-the-battle-of-algiers/25-the-battle-of-algiers.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_26-dunkirk-2017-film/26-dunkirk-2017-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9908_27-the-maltese-falcon-1941-film/27-the-maltese-falcon-1941-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_29-12-years-a-slave-film/29-12-years-a-slave-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_30-gravity-2013-film/30-gravity-2013-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9909_31-sunset-boulevard-film/31-sunset-boulevard-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_32-king-kong-1933-film/32-king-kong-1933-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_33-spotlight-film/33-spotlight-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990a_34-the-adventures-of-robin-hood/34-the-adventures-of-robin-hood.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_35-rashomon/35-rashomon.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_36-rear-window/36-rear-window.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990b_37-selma-film/37-selma-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_38-taxi-driver/38-taxi-driver.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_39-toy-story-3/39-toy-story-3.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990c_40-argo-2012-film/40-argo-2012-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_41-toy-story-2/41-toy-story-2.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_42-the-big-sick/42-the-big-sick.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_43-bride-of-frankenstein/43-bride-of-frankenstein.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990d_44-zootopia/44-zootopia.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_45-m-1931-film/45-m-1931-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_46-wonder-woman-2017-film/46-wonder-woman-2017-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990e_48-alien-film/48-alien-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_49-bicycle-thieves/49-bicycle-thieves.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_50-seven-samurai/50-seven-samurai.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad990f_51-the-treasure-of-the-sierra-madre-film/51-the-treasure-of-the-sierra-madre-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_52-up-2009-film/52-up-2009-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_53-12-angry-men-1957-film/53-12-angry-men-1957-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9910_54-the-400-blows/54-the-400-blows.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_55-logan-film/55-logan-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9911_57-army-of-shadows/57-army-of-shadows.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_58-arrival-film/58-arrival-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9912_59-baby-driver/59-baby-driver.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_60-a-streetcar-named-desire-1951-film/60-a-streetcar-named-desire-1951-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_61-the-night-of-the-hunter-film/61-the-night-of-the-hunter-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_62-star-wars-the-force-awakens/62-star-wars-the-force-awakens.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9913_63-manchester-by-the-sea-film/63-manchester-by-the-sea-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_64-dr.-strangelove/64-dr.-strangelove.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_66-vertigo-film/66-vertigo-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9914_67-the-dark-knight-film/67-the-dark-knight-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_68-touch-of-evil/68-touch-of-evil.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_69-the-babadook/69-the-babadook.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9915_72-rosemary27s-baby-film/72-rosemary27s-baby-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_73-finding-nemo/73-finding-nemo.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9916_74-brooklyn-film/74-brooklyn-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_75-the-wrestler-2008-film/75-the-wrestler-2008-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9917_77-l.a.-confidential-film/77-l.a.-confidential-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_78-gone-with-the-wind-film/78-gone-with-the-wind-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_79-the-good-the-bad-and-the-ugly/79-the-good-the-bad-and-the-ugly.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9918_80-skyfall/80-skyfall.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_82-tokyo-story/82-tokyo-story.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_83-hell-or-high-water-film/83-hell-or-high-water-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_84-pinocchio-1940-film/84-pinocchio-1940-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad9919_85-the-jungle-book-2016-film/85-the-jungle-book-2016-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991a_86-la-la-land-film/86-la-la-land-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_87-star-trek-film/87-star-trek-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991b_89-apocalypse-now/89-apocalypse-now.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_90-on-the-waterfront/90-on-the-waterfront.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_91-the-wages-of-fear/91-the-wages-of-fear.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991c_92-the-last-picture-show/92-the-last-picture-show.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_93-harry-potter-and-the-deathly-hallows-part-2/93-harry-potter-and-the-deathly-hallows-part-2.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_94-the-grapes-of-wrath-film/94-the-grapes-of-wrath-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991d_96-man-on-wire/96-man-on-wire.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_97-jaws-film/97-jaws-film.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_98-toy-story/98-toy-story.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_99-the-godfather-part-ii/99-the-godfather-part-ii.txt',\n",
    "                     'https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ad991e_100-battleship-potemkin/100-battleship-potemkin.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'ebert_reviews'\n",
    "#if not os.path.exists(folder_name):\n",
    "#    os.makedirs(folder_name)\n",
    "\n",
    "#for url in ebert_review_urls:\n",
    "#    response = requests.get(url)\n",
    "#    with open(oa.path.join(folder_name,\n",
    "#                           url.split('/')[-1]), mode='wb') as file:\n",
    "#        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(folder_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Text File Structure\n",
    "\n",
    "A text file refers to a file that uses a specific character set and contains no formatting, like italics or bolding. It also, has no media, like images or video. Lines of text are separated by newline characters or backslash end in Python. These characters are invisible in most software applications, like this text editor.\n",
    "\n",
    "* Encodings and Character Sets Articles\n",
    "    * The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) by [Joel Spolsky](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n",
    "    * What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text by [Joel Spolsky](http://kunststube.net/encoding/)\n",
    "\n",
    "\n",
    "* In Python 3, there is:\n",
    "    * one text type: str, which holds Unicode data and\n",
    "    * two byte types: bytes and bytearray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Text Files in Python\n",
    "\n",
    "We'll need to loop to iterate through all of the files in this folder to open and read each, then extract the bits of text that we need as separate pieces of data:\n",
    "\n",
    "* the first line, which is the movie title (to merge to the master dataset with)\n",
    "* the second line, which is the review URL (not necessary for the word cloud but nice to have)\n",
    "* everything from the third line onwards, which is the review text\n",
    "\n",
    "The Jupyter Notebook below contains template code that:\n",
    "\n",
    "* Creates an empty list, df_list, to which dictionaries will be appended. This list of dictionaries will eventually be converted to a pandas DataFrame (this is the most efficient way of building a DataFrame row by row).\n",
    "* Loops through each movie's Roger Ebert review text file in the ebert_reviews folder.\n",
    "* Opens each text file using a path generated by glob and passes it into a file handle called file.\n",
    "* Creates a DataFrame called df by converting df_list using the pd.DataFrame constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 for get the contents of text file\n",
    "df_lists = []\n",
    "folder = 'ebert_reviews'\n",
    "for ebert_review in os.listdir(folder):\n",
    "    with open(os.path.join(folder, ebert_review)) as file:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review_url</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dunkirk (2017)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/dunkirk-2017</td>\n",
       "      <td>Lean and ambitious, unsentimental and bombasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army of Shadows (L'Arm√©e des ombres) (1969)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>Jean-Pierre Melville's \"Army of Shadows\" is ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alien (1979)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>At its most fundamental level, \"Alien\" is a mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Bride of Frankenstein (1935)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>To a new world of gods and monsters.\\n\\nSo int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 400 Blows (Les Quatre cents coups) (1959)</td>\n",
       "      <td>http://www.rogerebert.com/reviews/great-movie-...</td>\n",
       "      <td>I demand that a film express either the joy of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0                                 Dunkirk (2017)   \n",
       "1    Army of Shadows (L'Arm√©e des ombres) (1969)   \n",
       "2                                   Alien (1979)   \n",
       "3               The Bride of Frankenstein (1935)   \n",
       "4  The 400 Blows (Les Quatre cents coups) (1959)   \n",
       "\n",
       "                                          review_url  \\\n",
       "0     http://www.rogerebert.com/reviews/dunkirk-2017   \n",
       "1  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "2  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "3  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "4  http://www.rogerebert.com/reviews/great-movie-...   \n",
       "\n",
       "                                         review_text  \n",
       "0  Lean and ambitious, unsentimental and bombasti...  \n",
       "1  Jean-Pierre Melville's \"Army of Shadows\" is ab...  \n",
       "2  At its most fundamental level, \"Alien\" is a mo...  \n",
       "3  To a new world of gods and monsters.\\n\\nSo int...  \n",
       "4  I demand that a film express either the joy of...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2 for get the contents of text file\n",
    "df_lists = []\n",
    "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
    "    with open(ebert_review, encoding='utf-8') as file:\n",
    "        title = file.readline()[:-1]\n",
    "        review_url = file.readline()[:-1]\n",
    "        review_text = file.read()\n",
    "        df_lists.append({'title': title,\n",
    "                         'review_url': review_url,\n",
    "                         'review_text': review_text})\n",
    "        \n",
    "df = pd.DataFrame(df_lists, columns=['title', 'review_url', 'review_text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Source: APIs (Application Programming Interfaces)\n",
    "\n",
    "At their simplest, APIs let you access data from the Internet in a reasonably easy manner. Twitter, Facebook, Instagram all have APIs. It doesn't have to be a company led thing though. There are tons of open source APIs. MediaWiki, which is a popular API for Wikipedia is open source. This is the API you'll be using in this lesson.\n",
    "\n",
    "**MediaWiki** is an API that hosts all of the Wikipedia data, and has a great [tutorial](https://www.mediawiki.org/wiki/API:Main_page#A_simple_example) on their website on how their API calls are structured. It's a nice and simple example and they explain the various moving parts:\n",
    "\n",
    "* The endpoint (important takeaway: there is nothing special about this URL!)\n",
    "* The format\n",
    "* The action\n",
    "* Action-specific parameters\n",
    "\n",
    "**wptools Library**\n",
    "\n",
    "There are a bunch of different access libraries for MediaWiki to satisfy the variety of programming languages that exist. Here is a [list](https://www.mediawiki.org/wiki/API:Client_code#Python) for Python. This is pretty standard for most APIs. For a MediaWiki, the most up to date and human readable one in Python is called [wptools](https://github.com/siznax/wptools). The analogous relationship for Twitter is:\n",
    "* MediaWiki API ‚Üí wptools\n",
    "* Twitter API ‚Üí tweepy\n",
    "\n",
    "wptools has an even simpler [tutorial](https://en.wikipedia.org/wiki/Mahatma_Gandhi) on their GitHub page using the Mahatma Gandhi Wikipedia page as a working example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a page info use Rotten Tomatoes API\n",
    "\n",
    "#import rtsimple as rt\n",
    "#rt.API_KEY = \"YOUR API KEY HERE\"\n",
    "#movie = rt.Movies('10489')\n",
    "#movie.ratings['audience_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a page image use MediaWiki API\n",
    "\n",
    "#import wptools\n",
    "#page = wptools.page('Mahatma_Gandhi')\n",
    "#page.get()\n",
    "#page.data['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. JSON File Structure\n",
    "\n",
    "Though JSON has six valid data types, two of them provide most of the format's flexibility for hierarchical data:\n",
    "\n",
    "* JSON objects <- python dictionary\n",
    "* JSON arrays <- python list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. JSON Files in Python\n",
    "\n",
    "This Reading and Writing JSON to a File in Python [article](http://stackabuse.com/reading-and-writing-json-to-a-file-in-python/) from Stack Abuse is also great, which outlines json.dump, json.dumps, json.load, and json.loads (four key json library methods) well.\n",
    "\n",
    "pandas also has JSON functions (the read_json function and the to_json DataFrame method), but the hierarchical advantage of JSON is wasted in pandas' tabular DataFrame so the uses are limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the wptools page object for the E.T. Wikipedia page\n",
    "#page = wptools.page(\"E.T._the_Extra-Terrestrial\").get()\n",
    "\n",
    "# Accessing the image attribute will return the images for this page\n",
    "#page.data['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Mashup: APIs, Downloading Files Programmatically, JSON\n",
    "\n",
    "With APIs, downloading files programmatically from the internet, and JSON under your belt, you now have all of the knowledge to download all of the movie poster images for the Roger Ebert review word clouds. \n",
    "\n",
    "1. Wikipedia Page Titles\n",
    "\n",
    "To access Wikipedia page data via the MediaWiki API with wptools (phew, that was a mouthful), you need each movie's Wikipedia page title, i.e., what comes after the last slash in en.wikipedia.org/wiki/ in the URL.\n",
    "\n",
    "2. Downloading Image Files\n",
    "\n",
    "Downloading images may seem tricky from a reading and writing perspective, in comparison to text files which you can read line by line, for example. But in reality, image files aren't special‚Äîthey're just binary files. To interact with them, you don't need special software (like Photoshop or something) that \"understands\" images. You can use regular file opening, reading, and writing techniques, like this:\n",
    "\n",
    "```\n",
    "import requests\n",
    "r = requests.get(url)\n",
    "with open(folder_name + '/' + filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "```\n",
    "\n",
    "But this technique can be error-prone. It will work most of the time, but sometimes the file you write to will be damaged. \n",
    "\n",
    "This type of error is why the requests library maintainers recommend using the PIL library (short for Pillow) and BytesIO from the io library for non-text requests, like images. They recommend that you access the response body as bytes, for non-text requests. For example, to create an image from binary data returned by a request:\n",
    "\n",
    "```\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "r = requests.get(url)\n",
    "i = Image.open(BytesIO(r.content))\n",
    "```\n",
    "\n",
    "Though we're going to use a loop to minimize repetition, here's how the major parts inside that loop will work, in order:\n",
    "\n",
    "* We're going to query the MediaWiki API using wptools to get a movie poster URL via each page object's image attribute.\n",
    "* Using that URL, we'll programmatically download that image into a folder called bestofrt_posters.\n",
    "\n",
    "The Jupyter Notebook below contains template code that:\n",
    "\n",
    "* Contains title_list, which is a list of all of the Wikipedia page titles for each movie in the Rotten Tomatoes Top 100 Movies of All Time list. This list is in the same order as the Top 100.\n",
    "* Creates an empty list, df_list, to which dictionaries will be appended. This list of dictionaries will eventually be converted to a pandas DataFrame.\n",
    "* Creates an empty folder, bestofrt_posters, to store the downloaded movie poster image files.\n",
    "* Creates an empty dictionary, image_errors, to fill to keep track of movie poster image URLs that don't work.\n",
    "* Loops through the Wikipedia page titles in title_list and:\n",
    "    * Stores the ranking of that movie in the Top 100 list based on its position in title_list. Ranking is needed so we can join this DataFrame with the master DataFrame later. We can't join on title because the titles of the Rotten Tomatoes pages and the Wikipedia pages differ.\n",
    "    * Uses try and except blocks to attempt to query MediaWiki for a movie poster image URL and to attempt to download that image. If the attempt fails and an error is encountered, the offending movie is documented in image_errors.\n",
    "    * Appends a dictionary with ranking, title, and poster_url as the keys and the extracted values for each as the values to df_list.\n",
    "* Inspects the images that caused errors and downloads the correct image individually (either via another URL in the image attribute's list or a URL from Google Images)\n",
    "* Creates a DataFrame called df by converting df_list using the pd.DataFrame constructor.\n",
    "\n",
    "Inside the \"for title in title_list:\" loop in the Jupyter Notebook below:\n",
    "\n",
    "* Fill in the images variable. This tests your API skills.\n",
    "* Fill in the first_image_url variable. This tests your JSON skills.\n",
    "* Fill in the r variable. This tests your programmatic downloading skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. Mashup Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = [\n",
    " 'The_Wizard_of_Oz_(1939_film)',\n",
    " 'Citizen_Kane',\n",
    " 'The_Third_Man',\n",
    " 'Get_Out_(film)',\n",
    " 'Mad_Max:_Fury_Road',\n",
    " 'The_Cabinet_of_Dr._Caligari',\n",
    " 'All_About_Eve',\n",
    " 'Inside_Out_(2015_film)',\n",
    " 'The_Godfather',\n",
    " 'Metropolis_(1927_film)',\n",
    " 'E.T._the_Extra-Terrestrial',\n",
    " 'Modern_Times_(film)',\n",
    " 'It_Happened_One_Night',\n",
    " \"Singin'_in_the_Rain\",\n",
    " 'Boyhood_(film)',\n",
    " 'Casablanca_(film)',\n",
    " 'Moonlight_(2016_film)',\n",
    " 'Psycho_(1960_film)',\n",
    " 'Laura_(1944_film)',\n",
    " 'Nosferatu',\n",
    " 'Snow_White_and_the_Seven_Dwarfs_(1937_film)',\n",
    " \"A_Hard_Day%27s_Night_(film)\",\n",
    " 'La_Grande_Illusion',\n",
    " 'North_by_Northwest',\n",
    " 'The_Battle_of_Algiers',\n",
    " 'Dunkirk_(2017_film)',\n",
    " 'The_Maltese_Falcon_(1941_film)',\n",
    " 'Repulsion_(film)',\n",
    " '12_Years_a_Slave_(film)',\n",
    " 'Gravity_(2013_film)',\n",
    " 'Sunset_Boulevard_(film)',\n",
    " 'King_Kong_(1933_film)',\n",
    " 'Spotlight_(film)',\n",
    " 'The_Adventures_of_Robin_Hood',\n",
    " 'Rashomon',\n",
    " 'Rear_Window',\n",
    " 'Selma_(film)',\n",
    " 'Taxi_Driver',\n",
    " 'Toy_Story_3',\n",
    " 'Argo_(2012_film)',\n",
    " 'Toy_Story_2',\n",
    " 'The_Big_Sick',\n",
    " 'Bride_of_Frankenstein',\n",
    " 'Zootopia',\n",
    " 'M_(1931_film)',\n",
    " 'Wonder_Woman_(2017_film)',\n",
    " 'The_Philadelphia_Story_(film)',\n",
    " 'Alien_(film)',\n",
    " 'Bicycle_Thieves',\n",
    " 'Seven_Samurai',\n",
    " 'The_Treasure_of_the_Sierra_Madre_(film)',\n",
    " 'Up_(2009_film)',\n",
    " '12_Angry_Men_(1957_film)',\n",
    " 'The_400_Blows',\n",
    " 'Logan_(film)',\n",
    " 'All_Quiet_on_the_Western_Front_(1930_film)',\n",
    " 'Army_of_Shadows',\n",
    " 'Arrival_(film)',\n",
    " 'Baby_Driver',\n",
    " 'A_Streetcar_Named_Desire_(1951_film)',\n",
    " 'The_Night_of_the_Hunter_(film)',\n",
    " 'Star_Wars:_The_Force_Awakens',\n",
    " 'Manchester_by_the_Sea_(film)',\n",
    " 'Dr._Strangelove',\n",
    " 'Frankenstein_(1931_film)',\n",
    " 'Vertigo_(film)',\n",
    " 'The_Dark_Knight_(film)',\n",
    " 'Touch_of_Evil',\n",
    " 'The_Babadook',\n",
    " 'The_Conformist_(film)',\n",
    " 'Rebecca_(1940_film)',\n",
    " \"Rosemary%27s_Baby_(film)\",\n",
    " 'Finding_Nemo',\n",
    " 'Brooklyn_(film)',\n",
    " 'The_Wrestler_(2008_film)',\n",
    " 'The_39_Steps_(1935_film)',\n",
    " 'L.A._Confidential_(film)',\n",
    " 'Gone_with_the_Wind_(film)',\n",
    " 'The_Good,_the_Bad_and_the_Ugly',\n",
    " 'Skyfall',\n",
    " 'Rome,_Open_City',\n",
    " 'Tokyo_Story',\n",
    " 'Hell_or_High_Water_(film)',\n",
    " 'Pinocchio_(1940_film)',\n",
    " 'The_Jungle_Book_(2016_film)',\n",
    " 'La_La_Land_(film)',\n",
    " 'Star_Trek_(film)',\n",
    " 'High_Noon',\n",
    " 'Apocalypse_Now',\n",
    " 'On_the_Waterfront',\n",
    " 'The_Wages_of_Fear',\n",
    " 'The_Last_Picture_Show',\n",
    " 'Harry_Potter_and_the_Deathly_Hallows_‚Äì_Part_2',\n",
    " 'The_Grapes_of_Wrath_(film)',\n",
    " 'Roman_Holiday',\n",
    " 'Man_on_Wire',\n",
    " 'Jaws_(film)',\n",
    " 'Toy_Story',\n",
    " 'The_Godfather_Part_II',\n",
    " 'Battleship_Potemkin'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Flashforward 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('bestofrt_master.csv')\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. Storing Data\n",
    "\n",
    "Storing is usually done after cleaning, but it's not always done, which excludes it from being a core part of the data wrangling process. Sometimes you just analyze and visualize and leave it at that, without saving your new data.\n",
    "\n",
    "Given the size of this dataset and that it likely won't be shared often, saving to a flat file like a CSV is probably the best solution. With pandas, saving your gathered data to a CSV file is easy. The `to_csv` DataFrame method is all you need and the only parameter required to save a file on your computer is the file path to which you want to save this file. Often specifying `index=False` is necessary too if you don't want the DataFrame index showing up as a column in your stored dataset. If you had a DataFrame, df, and wanted to save to a file named dataset.csv with no index column:\n",
    "\n",
    "`df.to_csv('dataset.csv', index=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. Relational Database Structure\n",
    "\n",
    "A database is an organized collection of data that is structured to facilitate the storage, retrieval, modification, and deletion of data. There are two main types of databases: relational databases and non-relational databases, with relational being the most popular.\n",
    "SQL, or Structured Query Language, is the standard language for communicating with relational databases.\n",
    "\n",
    "Let‚Äôs turn to Derek Steer, co-founder and CEO of Mode Analytics (a company that is building software for SQL-based data analysis), to introduce the basic structure of relational databases, their advantages and disadvantages, and how you can interact with them using SQL.\n",
    "\n",
    "[Cornell: Relational Databases - Not your Father‚Äôs Flat Files](https://www.cac.cornell.edu/education/Training/DataAnalysis/RelationalDatabases.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Relational Databases in Python\n",
    "\n",
    "In the context of data wrangling, we recommend that databases and SQL only come into play for gathering data or storing data. That is:\n",
    "\n",
    "* **Connecting to a database and importing data** into a pandas DataFrame (or the analogous data structure in your preferred programming language), then assessing and cleaning that data, or\n",
    "* **Connecting to a database and storing data** you just gathered (which could potentially be from a database), assessed, and cleaned\n",
    "\n",
    "The two scenarios above can be further broken down into three main tasks:\n",
    "\n",
    "* Connecting to a database in Python\n",
    "* Storing data from a pandas DataFrame in a database to which you're connected, and\n",
    "* Importing data from a database to which you're connected to a pandas DataFrame\n",
    "\n",
    "For the example in this lesson, we're going to do these in order:\n",
    "\n",
    "* Connect to a database. We'll connect to a SQLite database using SQLAlchemy, a database toolkit for Python.\n",
    "* Store the data in the cleaned master dataset in that database. We'll do this using pandas' to_csv DataFrame method.\n",
    "* Then read the brand new data in that database back into a pandas DataFrame. We'll do this using pandas' read_csv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sqlalchemy import create_engine\n",
    "\n",
    "# Create SQLAlchemy Engine and empty bestofrt database\n",
    "# bestofrt.db will not show up in the Jupyter Notebook dashboard yet\n",
    "\n",
    "#engine = create_engine('sqlite:///bestofrt.db')\n",
    "\n",
    "# Store cleaned master DataFrame ('df') in a table called master in bestofrt.db\n",
    "# bestofrt.db will be visible now in the Jupyter Notebook dashboard\n",
    "\n",
    "#df.to_sql('master', engine, index=False)\n",
    "#df_gather = pd.read_sql('SELECT * FROM master', engine)\n",
    "#df_gather.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. Other File Formats\n",
    "\n",
    "The types of files you mastered in this lesson are the ones you'll interact with for the vast majority of your wrangling projects in the future. Again, these were:\n",
    "\n",
    "* Flat files (e.g. CSV and TSV)\n",
    "* HTML files\n",
    "* JSON files\n",
    "* TXT files\n",
    "* Relational database files\n",
    "\n",
    "Additional, less common file formats include:\n",
    "\n",
    "* [Excel files](https://www.lifewire.com/what-is-an-xlsx-file-2622540)\n",
    "* [Pickle files](https://stackoverflow.com/questions/7501947/understanding-pickling-in-python)\n",
    "* [HDF5 files](http://neondataskills.org/HDF5/About)\n",
    "* [SAS files](http://whatis.techtarget.com/fileformat/SAS-SAS-program-file)\n",
    "* [STATA files](http://faculty.econ.ucdavis.edu/faculty/cameron/stata/stataintro.html)\n",
    "\n",
    "pandas has [functions](http://pandas.pydata.org/pandas-docs/stable/api.html#input-output) to read (and write, to most of them) these files. Also, you now have the foundational understanding of gathering and file formats in general, so learning these additional formats won't be too hard if you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. You Can Iterate\n",
    "\n",
    "Remember, data wrangling can be an iterative process. Whether you're in the gather, assess, or clean phase, you can iterate on them. Starting small and iterating is very okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26. Gathering Summary\n",
    "\n",
    "Gathering is the first step in the data wrangling process:\n",
    "\n",
    "* Gather\n",
    "* Assess\n",
    "* Clean\n",
    "\n",
    "Depending on the source of your data, and what format it's in, the steps in gathering data vary.\n",
    "\n",
    "The high-level gathering process:\n",
    "\n",
    "* obtaining data (downloading a file from the internet, scraping a web page, querying an API, etc.)\n",
    "* importing that data into your programming environment (e.g. Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. Conclusion\n",
    "\n",
    "You gather data from multiple different sources, you extract the data from a file handed to you, you scrape data off of a web page, downloaded files from the internet, and accessed data from an API, then put it all in a database. And all of this data was in completely different formats: TSV, HTML, TXT, JSON, then eventually a database. \n",
    "\n",
    "Becoming a master data gatherer requires a bunch of skills since data comes in so many different formats and from so many different sources in practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
